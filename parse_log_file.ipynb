{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulations with .log files using Pandas library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, let's read .log file and parse it using pandas into a convenient table, and print out top 5 elements of the table using method .head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME_OF_FILE = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_of_all_lines(file_name=NAME_OF_FILE):\n",
    "    # Create a dataframe object and collect data from the log file\n",
    "    data_lines = []\n",
    "    with open(file_name, \"r\") as file:\n",
    "        for line in file:\n",
    "            data_lines.append(line.strip())\n",
    "\n",
    "    return pd.DataFrame(data_lines, columns=[\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_TABLE = get_table_of_all_lines()\n",
    "\n",
    "top_5_elements = ORIGINAL_TABLE.head()\n",
    "# print(top_5_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we have a specific log formatting in the source code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in this case, our log convention is going to be\n",
    "\n",
    "**time - level - message**\n",
    "\n",
    "and we need a table, with these three columns. Let's make such a table.\n",
    "\n",
    "Note:\n",
    "\n",
    "- a line of the unknown format joins to the previous log-lines `\"message\"`.\n",
    "\n",
    "- 'time' column elements become actual `datetime` objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_of_logs(file_name=NAME_OF_FILE):\n",
    "    data_lines = []\n",
    "    split_sign = \" - \"\n",
    "    how_many_columns = 3\n",
    "    with open(file_name, \"r\") as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                time, level, message = line.strip().split(split_sign, how_many_columns-1) # because start counting from 0\n",
    "                data_lines.append({\"time\": time, \"level\": level, \"message\": message})\n",
    "            except ValueError as e:\n",
    "                # lines that do not fit our convention are joined with the last conventional log message we had\n",
    "                data_lines[-1][\"message\"] += f\"\\n{line.strip()}\"\n",
    "\n",
    "    result = pd.DataFrame(data_lines)\n",
    "    # parse time\n",
    "    result[\"time\"] = pd.to_datetime(result[\"time\"], format=\"mixed\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGS_TABLE = get_table_of_logs()\n",
    "\n",
    "\n",
    "top_5_elements = LOGS_TABLE.head()\n",
    "# print(top_5_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when we have a table, let's manipulate it in some way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a separate table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERRORS_TABLE = LOGS_TABLE[LOGS_TABLE[\"level\"] == \"ERROR\"]\n",
    "\n",
    "top_5_elements = ERRORS_TABLE.head()\n",
    "# print(top_5_elements)\n",
    "\n",
    "sizes_of_the_error_table = ERRORS_TABLE.shape\n",
    "# print(f\"The number of rows: {sizes_of_the_error_table[0]}\")\n",
    "# print(f\"The number of columns: {sizes_of_the_error_table[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of rows is the amount of errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count many stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of unique error messages\n",
    "unique_error_count = ERRORS_TABLE[\"message\"].nunique()\n",
    "\n",
    "# Count of all error messages (including duplicates)\n",
    "all_error_count = sizes_of_the_error_table[0]  # number of ERRORS_TABLE rows\n",
    "\n",
    "# For a detailed count of each unique error message\n",
    "error_message_counts = ERRORS_TABLE[\"message\"].value_counts() # it's a table unique_message - how_many\n",
    "\n",
    "# print(\"Unique error messages count:\", unique_error_count)\n",
    "# print(\"Total error messages count:\", all_error_count)\n",
    "# print(\"\\nCounts of each unique error message:\\n\", error_message_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of errors containing the word 'pending' in the message\n",
    "pending_error_count = ERRORS_TABLE[\n",
    "    ERRORS_TABLE[\"message\"].str.contains(\"pending\")\n",
    "].shape[0]\n",
    "\n",
    "# print(\"\\nCounts of error messages that have word 'pending' in it :\\n\", pending_error_count)\n",
    "first_error_time = ERRORS_TABLE[\"time\"].iloc[0]\n",
    "last_error_time = ERRORS_TABLE[\"time\"].iloc[-1]\n",
    "\n",
    "# print(f\"The first error occurred at: {firt_error_time}\")\n",
    "# print(f\"The last error occurred at: {last_error_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing how to count elements of the table, or to filter a table with respect to some criteria, you can create any statistics report you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the counts\n",
    "my_statistics = {\n",
    "    \"log file name\": NAME_OF_FILE,\n",
    "    \"first error time\": first_error_time,\n",
    "    \"last error date\": last_error_time,\n",
    "    \"unique error messages\": unique_error_count,\n",
    "    \"total error messages\": all_error_count,\n",
    "    \"pending error messages\": pending_error_count,\n",
    "}\n",
    "\n",
    "\n",
    "def save_statistics(my_statistics=my_statistics):\n",
    "    column1 = my_statistics.keys()\n",
    "    column2 = my_statistics.values()\n",
    "\n",
    "    counts_df = pd.DataFrame(data=column2, index=column1)\n",
    "\n",
    "    counts_df.to_excel(\"error_counts.xlsx\", header=False)\n",
    "\n",
    "\n",
    "# save_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also save to csv, json, and txt (txt is going to be manually though), and [many other formats](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html).\n",
    "\n",
    "See documentation of DataFrame object for further details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
